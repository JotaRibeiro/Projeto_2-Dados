{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome:** João Pedro Henneberg Ribeiro\n",
    "\n",
    "**Nome:** João Nogueira Roxo da Fonseca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@JoaoHenneberg***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Gabigol'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 500\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_raw = pd.read_excel(\"Gabigol.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = set(dados_raw.Treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_ = pd.Series(list(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_.to_excel(\"Gabigol_base.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando as Tabelas\n",
    "tabela_teste = pd.read_excel('Gabigol.xlsx', sheet_name = \"Teste\")\n",
    "tabela_treinamento =pd.read_excel('Gabigol.xlsx', sheet_name = \"Treinamento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classificando os Tweets\n",
    "ruim = tabela_treinamento.loc[tabela_treinamento[\"Classificação\"] == 0]\n",
    "bom = tabela_treinamento.loc[tabela_treinamento[\"Classificação\"] == 1]\n",
    "indiferente = tabela_treinamento.loc[tabela_treinamento[\"Classificação\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colocando a Tabela em um Texto\n",
    "ruim_texto = \" \".join(ruim[\"Treinamento\"])\n",
    "bom_texto = \" \".join(bom[\"Treinamento\"])\n",
    "indiferente_texto = \" \".join(indiferente[\"Treinamento\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpando o Código(Limpando links)\n",
    "ruim_texto = re.sub(r\"http\\S+\", \"\", ruim_texto)\n",
    "bom_texto = re.sub(r\"http\\S+\", \"\", bom_texto)\n",
    "indiferente_texto = re.sub(r\"http\\S+\", \"\", indiferente_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpando o Código(Limpando o resto)\n",
    "ruim_limpo = cleanup(ruim_texto.lower())\n",
    "bom_limpo = cleanup(bom_texto.lower())\n",
    "indiferente_limpo = cleanup(indiferente_texto.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando a Tabela de Frequências\n",
    "freq_ruim = pd.Series(ruim_limpo.split())\n",
    "freq_bom = pd.Series(bom_limpo.split())\n",
    "freq_indiferente = pd.Series(indiferente_limpo.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Juntando as Palavras Repetidas\n",
    "tabela_ruim = freq_ruim.value_counts()\n",
    "tabela_bom = freq_bom.value_counts()\n",
    "tabela_indiferente = freq_indiferente.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando a Tabela com a Frequência Relativa\n",
    "tabela_ruim_relativa = freq_ruim.value_counts(True)\n",
    "tabela_bom_relativa = freq_bom.value_counts(True)\n",
    "tabela_indiferente_relativa = freq_indiferente.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo a União Entre as Tabelas de Bom/Indiferente e Ruim/Indiferente\n",
    "set_ruim = set(tabela_ruim_relativa.index)\n",
    "set_bom = set(tabela_bom_relativa.index)\n",
    "set_indiferente = set(tabela_indiferente_relativa.index)\n",
    "\n",
    "uniao_ruim_ind = set_ruim.union(set_indiferente)\n",
    "uniao_bom_ind = set_bom.union(set_indiferente)\n",
    "\n",
    "uniao_total = uniao_ruim_ind.union(uniao_bom_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo o Total para ser Usado no Cálculo da Probabilidade\n",
    "ruim_absoluto = tabela_ruim + 1\n",
    "total_ruim = sum(ruim_absoluto) + len(uniao_total)\n",
    "\n",
    "bom_absoluto = tabela_bom + 1\n",
    "total_bom = sum(bom_absoluto) + len(uniao_total)\n",
    "\n",
    "indiferente_absoluto = tabela_indiferente + 1\n",
    "total_indiferente = sum(indiferente_absoluto) + len(uniao_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando a Palavra Dado Bom/Ruim/Indiferente\n",
    "prob_ruim = tabela_ruim.sum()/total_ruim\n",
    "\n",
    "prob_bom = tabela_bom.sum()/total_bom\n",
    "\n",
    "prob_indiferente = tabela_indiferente.sum()/total_indiferente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28613763582482715"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probabilidade do Tweet ser Ruim\n",
    "prob_ruim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4185053380782918"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probabilidade do Tweet ser Bom\n",
    "prob_bom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5522745411013568"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probabilidade do Tweet ser Indiferente\n",
    "prob_indiferente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Montando Fórmula de Classificação dos Tweets\n",
    "def concatena(tweet):\n",
    "    return tweet\n",
    "\n",
    "tweets_juntos = tabela_teste.Teste.apply(concatena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_teste = pd.read_excel('Gabigol.xlsx', sheet_name = \"Teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_varridos = []\n",
    "for mensagem in tweets_juntos:\n",
    "    tweets_varridos.append(cleanup(mensagem.lower())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando o Código de Classificação\n",
    "lista_classificacao = []\n",
    "\n",
    "d_lista_bom = tabela_bom[1]\n",
    "d_lista_ruim = tabela_ruim[1]\n",
    "d_lista_indiferente = tabela_indiferente[1]\n",
    "d = d_lista_bom + d_lista_ruim + d_lista_indiferente\n",
    "\n",
    "def probabilidade(palavra):\n",
    "    if palavra in tabela_bom:\n",
    "        k = tabela_bom[palavra]\n",
    "    else:\n",
    "        k = 0\n",
    "    if palavra in tabela_ruim:\n",
    "        J = tabela_ruim[palavra]\n",
    "    else:\n",
    "        J = 0\n",
    "    if palavra in tabela_indiferente:\n",
    "        l = tabela_indiferente[palavra]\n",
    "    else:\n",
    "        l = 0\n",
    "    prob_bom =( k +1)/(len(freq_bom) + d_lista_bom)\n",
    "    prob_ruim =(J + 1)/(len(freq_ruim) + d_lista_ruim) \n",
    "    prob_indiferente =(l + 1)/(len(freq_indiferente) + d_lista_indiferente) \n",
    "    \n",
    "    return [prob_bom, prob_ruim, prob_indiferente]\n",
    "\n",
    "\n",
    "for tweet in tweets_varridos:\n",
    "    periodo = tweet.split()\n",
    "    lista_palavras = []\n",
    "    for elemento in periodo:\n",
    "        lista_palavras.append(elemento)\n",
    "        bom = 1\n",
    "        ruim = 1\n",
    "        indiferente = 1\n",
    "        for palavra in lista_palavras:\n",
    "            if palavra in tabela_bom_relativa and palavra in tabela_indiferente_relativa and palavra in tabela_ruim_relativa:\n",
    "                bom *= tabela_bom_relativa[palavra]                                                           #Normal\n",
    "                ruim *= tabela_ruim_relativa[palavra]                                                         #Normal\n",
    "                indiferente *= tabela_indiferente_relativa[palavra]                                           #Normal\n",
    "            elif palavra in tabela_bom_relativa and palavra not in tabela_indiferente_relativa and palavra not in tabela_ruim_relativa:\n",
    "                bom *= tabela_bom_relativa[palavra]                                                           #Normal\n",
    "                ruim = probabilidade(palavra)[1]*ruim                                                         #LaPlace\n",
    "                indiferente = probabilidade(palavra)[2]*indiferente                                           #LaPlace    \n",
    "            elif palavra in tabela_bom_relativa and palavra not in tabela_indiferente_relativa and palavra in tabela_ruim_relativa:\n",
    "                bom *= tabela_bom_relativa[palavra]                                                           #Normal\n",
    "                ruim *= tabela_ruim_relativa[palavra]                                                         #Normal\n",
    "                indiferente = probabilidade(palavra)[2]*indiferente                                           #LaPlace    \n",
    "            elif palavra in tabela_bom_relativa and palavra in tabela_indiferente_relativa and palavra not in tabela_ruim_relativa:\n",
    "                bom *= tabela_bom_relativa[palavra]                                                           #Normal\n",
    "                ruim = probabilidade(palavra)[1]*ruim                                                         #LaPlace\n",
    "                indiferente *= tabela_indiferente_relativa[palavra]                                           #Normal    \n",
    "            \n",
    "            elif palavra not in tabela_bom_relativa and palavra in tabela_indiferente_relativa and palavra in tabela_ruim_relativa:\n",
    "                bom = probabilidade(palavra)[0]*bom                                                           #laPlace\n",
    "                ruim *= tabela_ruim_relativa[palavra]                                                         #Normal\n",
    "                indiferente *= tabela_indiferente_relativa[palavra]                                           #Normal\n",
    "            elif palavra not in tabela_bom_relativa and palavra not in tabela_indiferente_relativa and palavra in tabela_ruim_relativa:\n",
    "                bom = probabilidade(palavra)[0]*bom                                                           #laPlace\n",
    "                ruim = probabilidade(palavra)[1]*ruim                                                         #Normal\n",
    "                indiferente = probabilidade(palavra)[2]*indiferente                                           #LaPlace  \n",
    "            elif palavra not in tabela_bom_relativa and palavra in tabela_indiferente_relativa and palavra not in tabela_ruim_relativa:\n",
    "                bom = probabilidade(palavra)[0]*bom                                                           #laPlace\n",
    "                ruim = probabilidade(palavra)[1]*ruim                                                         #LaPlace\n",
    "                indiferente *= tabela_indiferente_relativa[palavra]                                           #Normal\n",
    "            else:\n",
    "                bom = probabilidade(palavra)[0]*bom                                                           #laPlace\n",
    "                ruim = probabilidade(palavra)[1]*ruim                                                         #LaPlace\n",
    "                indiferente = probabilidade(palavra)[2]*indiferente                                           #LaPlace    \n",
    "            \n",
    "        prob_gosta_frase = prob_bom * bom \n",
    "        prob_desgosta_frase = prob_ruim * ruim\n",
    "        prob_indiferente_frase = prob_indiferente * indiferente\n",
    "        \n",
    "        if prob_gosta_frase > prob_desgosta_frase and prob_gosta_frase > prob_indiferente_frase:\n",
    "            lista_classificacao.append(\"1\")\n",
    "        if prob_desgosta_frase > prob_gosta_frase and prob_desgosta_frase > prob_indiferente_frase:\n",
    "            lista_classificacao.append(\"0\")\n",
    "        else:\n",
    "            lista_classificacao.append(\"2\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando a Porcentagem de Bom/Ruim/Indiferente do Classificador\n",
    "pos = 0\n",
    "falso_pos = 0\n",
    "neg = 0\n",
    "falso_neg = 0\n",
    "total = len(tabela_teste[\"Classificação\"])\n",
    "irrel = 0\n",
    "bom = 0\n",
    "ruim = 0\n",
    "\n",
    "for [e,i] in zip(tabela_teste[\"Classificação\"], tabela_teste[\"Teste\"]):\n",
    "    if e == 0:\n",
    "        if i == 0:\n",
    "            pos += 1\n",
    "        else: \n",
    "            falso_neg += 1\n",
    "    elif e == 1:\n",
    "        if i == 1:\n",
    "            pos += 1\n",
    "        else: \n",
    "            falso_neg += 1\n",
    "    elif e == 2:            \n",
    "        if i == 2:\n",
    "            neg +=1\n",
    "        else:\n",
    "            falso_pos +=1        \n",
    "            \n",
    "for e in tabela_teste[\"Classificação\"]:\n",
    "    if e==1:\n",
    "        bom +=1\n",
    "    elif e==2:\n",
    "        irrel +=1\n",
    "    else:\n",
    "        ruim += 1\n",
    "        \n",
    "porcentagem_bom = bom*100/300\n",
    "porcentagem_ruim = ruim*100/300\n",
    "porcentagem_irrel = irrel*100/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.666666666666664"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porcentagem_bom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porcentagem_ruim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.333333333333336"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porcentagem_irrel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando a Porcentagem da Classificação Feita Manualmente\n",
    "porcentagem_bom_manual = (len(bom)/450)*100\n",
    "porcentagem_ruim_manual = (len(ruim)/450)*100\n",
    "porcentagem_irrel_manual = (len(indiferente)/450)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.222222222222225"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porcentagem_bom_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.111111111111112"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porcentagem_ruim_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.66666666666667"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porcentagem_irrel_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a análise das porcentagens de acerto do classificador, podemos concluir que apesar de ter análisado corretamente grande parte dos tweets, o classificador do código apresenta certas falhas(8,4% em Tweets \"Bons\", 5,1% em Tweets \"Ruins\" e 3,3% em Tweets \"Indiferentes\"). Isso pode ocorrer devido a palavras nos tweets usam um certo tipo de ironia, ou até dupla negação. Como a ironia se classifica como uma inversão do real significado de algo em determinado contexto, é comum o código não interpretar tais ironias, já  que somente são compreendidas com a compreensão do contexto em que a palavra está inserida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma possível melhoria para o código poderia ser implementar mais parâmetros para divisão das categorias, ao invés de somente 3 como feito no código. Com isso, seria possível fazer uma varredura mais precisa no código, já que teriam mais possibilidades de classificação de diversos tweets diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além do aumento das divisões dos códigos, outra possível saída para a redução dos erros seria de um classificador com um código mais aprofundado, que baseado nas palavras no contexto do Tweet, seja capaz de identificar se uma palavra específica está sendo usada no seu sentido conotativo ou denotativo. Com tal aprofundamento, as classificações seriam muito mais precisas e exatas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/ **Link que ajuda nas probabilidades**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
